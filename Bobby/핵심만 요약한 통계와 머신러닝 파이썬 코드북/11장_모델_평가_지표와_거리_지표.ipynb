{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제32회 ADP 실기 대비 - 핵심만 요약한 통계와 머신러닝 파이썬 코드북"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 시각화 설정\n",
    "plt.rcParams['font.family'] = 'Malgun Gothic' # 한글 폰트 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 설정\n",
    "\n",
    "# Colab 한글 폰트 설정\n",
    "# !sudo apt-get install -y fonts-nanum\n",
    "# !sudo fc-cache -fv\n",
    "# !rm ~/.cache/matplotlib -rf\n",
    "# plt.rcParams['font.family'] = 'NanumBarunGothic'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11장. 모델 평가 지표와 거리 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-1. 회귀모델 평가 지표"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ME (Mean Error)\n",
    "- 실제값과 예측값의 차이를 평균 계산한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE (Mean Absolute Error)\n",
    "- 실제값과 예측값의 차이를 절댓값으로 변환해 평균을 계산한 것이다.\n",
    "- MAE는 에러에 절댓값을 취하기 때문에 에러의 크기 그대로 반영한다.\n",
    "- 에러에 따른 손실이 선형적으로 올라가야 하거나 이상치가 많을 때 적합하다.\n",
    "- MAE는 이상치의 영향을 상대적으로 줄여주는 평가 지표이다.\n",
    "- 하나의 대푯값으로 예측할 때 MAE를 최소화하는 예측값은 중앙값이다.\n",
    "- 지표가 직관적이며 예측변수와 단위가 같아 이해가 쉽다.\n",
    "- 기온을 예측하는 모델의 MAE가 3이라면 이 모델은 평균적으로 3도 정도를 잘못 예측하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반면, 잔차에 절댓값을 씌우기 때문에 실제 값에 대해 과소예측(Under-estimates)인지 과대예측(Over-estimates)인지 파악하기 힘들다.\n",
    "- 예를 들어, 삼성전자의 주가를 예측하는 모델의 MAE가 1000이라면, 이 모델이 평균적으로 주가를 1000원을 높게 예측하는지 1000원을 낮게 예측하는지 파악하기 힘들다.\n",
    "- 또한, 스케일에 의존적이다. 이는 MAE, MSE, RMSE가 동일하게 가지는 단점이다.\n",
    "- 예를 들어, 비트코인의 가격이 35,000,000원이고 이더리움의 가격이 1,000,000원 일때 두 암호화폐의 가격을 예측하는 모델의 MAE가 동일하게 10,000이라고 해보자. 이들은 분명 동일한 에러율이 아님에도 불구하고 MAE 숫자 자체는 동일하다.\n",
    "- sklearn.metrics.mean_absolute_error(y_true, y_pred,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAPE (Mean Absolute Percentage Error)\n",
    "- MAE를 퍼센트로 변환한 것이다.\n",
    "- 예측값 대비 잔차의 비율을 의미하며, 주로 다른 시계열 모형의 적합치를 비교하는 데 사용한다.\n",
    "- 값이 작을수록 적합도가 높다는 것을 의미한다.\n",
    "- 이 지표의 장점은 이해하기 쉽다는 것이다. 예를 들어, 공연석의 규모를 예측하는 모델의 MAPE가 3인 경우 실제 공연석의 예매량과 예측 예매량 비율이 3% 정도 차이난다고 해석할 수 있다.\n",
    "- 또한, 비율 변수이기 때문에 모델 간 성능을 비교하기 용이하다. 예를 들어, 비트코인의 가격을 예측하는 모델의 MAPE가 3이고 이더리움의 가격을 예측하는 모델의 MAPE가5일 때 MAPE를 기반으로 판단하여 비트코인의 가격을 예측하는 모델이 더 우수하다고 평가할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 반면, 실제 값에 대해 과대예측 혹은 과소예측 여부를 파악하기 힘들다는 단점이 있다.\n",
    "- 또한, 비율로 해석할 때 의미가 있는 값에만 적용할 수 있다. 예를 들어, 기온을 예측하는 모델의 경우 MAPE로의 해석이 유효하지 않다.\n",
    "- 게다가 실제 값이 0이 포함될 경우 MAPE를 계산할 수 없다. 예를 들어, 10분 간격으로 서울시의 버스 수요를 예측해본다고 해보자.\n",
    "    - 이 때 10분의 interval 동안 수요가 0인 구간이 존재한다면 MAPE는 zero-division error를 반환한다.\n",
    "- 마지막으로, 실제 정답이 0에 가까운 매우 작은 값인 경우 MAPE 값이 매우 커질 수 있다는 단점이 있다.\n",
    "- sklearn.metrics.mean_absolute_percentage_error(y_true, y_pred, )\n",
    "- np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPE (Mean Percentage Error)\n",
    "- MAPE에서 절댓값을 제외한 지표이다.\n",
    "- ME와 MAE가 척도 문제를 가지고 있는 반면, MPE와 MAPE는 0~100%로 표준화를 해서 척도 문제가 없다는 장점이 있다.\n",
    "- 값이 0에 근접할수록 시계열 예측 모델이 잘 적합 되었다고 평가할 수 있고, MAE의 부호로 과대 혹은 과소 예측의 방향을 파악할 수 있다.\n",
    "- 또한, 실제 값에 대해 과소, 과대 예측 여부를 파악할 수 있다. MPE가 양수이면 과소 예측, 음수이면 과대 예측이다.\n",
    "- 단점은 지표 자체가 직관적이지 않으며 예측변수와 단위가 다르다는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE (Mean Squared Error)\n",
    "- MSE는 실제값과 예측값의 차이를 제곱해 평균을 계산한 것이다.\n",
    "- 장점은 지표 자체가 직관적이라는 것인 반면, 예측 변수와 단위가 다르며, 스케일에 의존적이라는 단점이 있다.\n",
    "- 또한, 잔차를 제곱하기 때문에 이상치에 민감하며, 1 미만의 에러는 더 작아지고 그 이상의 에러는 더 커진다.\n",
    "- 마지막으로 실제 값에 대해 과소, 과대 예측 여부를 알 수 없다.\n",
    "- sklearn.metrics.mean_squared_error(y_true, y_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE (Root mean squared error)\n",
    "- 잔차의 제곱에 대한 평균 값에 루트를 씌운 것이다.\n",
    "- MSE값은 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있어 MSE에 루트를 씌운 RMSE 값을 쓴다.\n",
    "- RMSE 값을 최소화 했을 때의 결과가 최대가능도 방법의 결과와 같아지는 등 통계학적으로 큰 의미를 가지는 평가지표이다.\n",
    "- 지표 자체가 직관적이며 예측 변수와 단위가 같다는 장점을 가진다.\n",
    "- 또한, 제곱된 잔차를 다시 루트로 풀어주기 때문에 잔차를 제곱해서 생기는 값의 왜곡이 MSE에 비해 좀 덜하다.\n",
    "- 반면, 이상치의 영향을 받기 쉬우므로 이상치를 제외한 처리 등을 미리 해두지 않으면 이상치에 과적합한 모델을 만들 가능성이 있다.\n",
    "- 또한, 실제 값에 대해 과소, 과대 예측 여부를 파악하기 힘들다. 마지막으로 스케일에 의존적이다.\n",
    "- np.sqrt(MSE)\n",
    "- statsmodels.tools.eval_measures.rmse(y_true, y_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ (= Explained Variance Score)\n",
    "- 결정계수를 말하며, 데이터에 대한 설명력을 0~1로 나타낸다.\n",
    "- sklearn.metrics.r2_score(y_true, y_pred, )\n",
    "- sklearn.metrics.explained_variance_score(y_true, y_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSLE (Mean Squared Log Error)\n",
    "- MSE에 로그를 적용한 지표이다.\n",
    "- sklearn.metrics.mean_squared_log_error(y_true, y_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSLE (Root Mean Squared Log Error)\n",
    "- 실제값과 예측값의 로그를 각각 취한 후 그 차의 제곱평균제곱근으로 계산되는 지표이다.\n",
    "- RMSE를 최소화하면 RMSLE가 최소화 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIC (Akaike's Information Criterion)\n",
    "- 서로 다른 선형 회귀 모형의 성능을 비교할 때 사용한다.\n",
    "- 조정 결정 계수 (Adjusted $R^2$)와 함께 최대 가능도에 독립변수의 개수에 대한 손실(Penalty)을 반영하는 방법을 정보량 규준이라고 하며 손실 가중치의 계산법에 따라 AIC, BIC 두 가지를 사용한다.\n",
    "- AIC는 모형과 데이터의 확률 분포 사이의 kullback-Leibler 수준을 가장 크게 하기 위한 시도에서 나왔다. 값이 적을 수록 올바른 모형에 가깝다.\n",
    "- p는 설명변수의 개수, n은 데이터의 개수, $log{L_i}$는 최대로그가능도를 말한다.\n",
    "- $-2log{L_i} + 2 * (p+1) - 2$로 구한다. (절편이 있는 경우 p+1, 없으면 p)\n",
    "- statsmodels.tools.eval_measures.aic(llf, nobs, df_modelwc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BIC (Bayesian Information Criterion)\n",
    "- AIC와 비슷하지만 변수 추가에 대해 더 강한 벌점을 준다.\n",
    "- p는 설명변수의 개수, n은 데이터의 개수, $log{L_i}$는 최대로그가능도를 말한다.\n",
    "- $-2log{L_i} + log(n) * (p+1) - 2$로 구한다. (절편이 있는 경우 p+1, 없으면 p)\n",
    "- statsmodels.tools.eval_measures.bic(llf, nobs, df_modelwc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AIC, BIC, 가능도에 대한 상세한 설명은 <8-1-2. 다중 선형 회귀>에서 다룬다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 데이터 불러오기\n",
    "X, y = load_diabetes()['data'], load_diabetes()['target']\n",
    "\n",
    "# 데이터 표준화 및 분할\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# 선형 회귀 적합 및 예측\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred1 = lr.predict(X_test)\n",
    "\n",
    "# SVM 회귀 적합 및 예측\n",
    "svr = SVR()\n",
    "svr.fit(X_train, y_train)\n",
    "pred2 = svr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Linear regression Vs. SVM\n",
      "title: 44.07 Vs. 57.05\n",
      "title: 40.83 Vs. 47.95\n",
      "title: 3050.76 Vs. 4683.59\n",
      "title: 55.23 Vs. 68.44\n",
      "title: 0.43 Vs. 0.13\n",
      "title: 0.19 Vs. 0.24\n",
      "title: 0.44 Vs. 0.49\n"
     ]
    }
   ],
   "source": [
    "# 2개의 회귀모델 평가 및 비교\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "from statsmodels.tools.eval_measures import rmse, rmspe\n",
    "\n",
    "def MAPE(y_true, y_pred):\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    return mape\n",
    "\n",
    "def RMSLE(y_true, y_pred):\n",
    "    rmsle = np.sqrt(mean_squared_log_error(y_true, y_pred))\n",
    "    return rmsle\n",
    "\n",
    "titles = ['MAE', 'MAPE', 'MSE', 'RMSE', 'R2', 'MSLE', 'RMSLE']\n",
    "functions = [mean_absolute_error, MAPE, mean_squared_error, rmse, r2_score, mean_squared_log_error, RMSLE]\n",
    "\n",
    "print(\">> Linear regression Vs. SVM\")\n",
    "for title, function in zip(titles, functions):\n",
    "    score1 = function(y_test, pred1)\n",
    "    score2 = function(y_test, pred2)\n",
    "    print(f\"title: {round(score1, 2)} Vs. {round(score2, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-2. 분류모델 평가 지표\n",
    "- 분류 결과는 True Positive, False Negative(=Type 2 error), False Positive(=Type 1 error), True Negative로 구분할 수 있다.\n",
    "- TP는 1을 1로 맞게 예측한 데이터의 개수, FN은 1을 0으로 잘못 예측한 데이터의 개수, FP는 0을 1로 잘못 예측한 데이터의 개수, TN은 0을 0으로 맞게 예측한 데이터의 개수를 의미한다.\n",
    "- 이 분류 결과를 기반으로 분류 모델의 성능을 평가하는 아래와 같은 지표들이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy\n",
    "- 전체 데이터 중 맞게 분류한 데이터의 비율로서 정확도를 의미한다.\n",
    "- (TP + TN) / (TP + TN + FP + FN)로 구한다.\n",
    "- sklearn.metrics.accuracy_score(y_true, y_pred, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision\n",
    "- 예측을 1이라고한 데이터 중 1로 맞게 예측한 데이터의 비율로서 정밀도를 의미한다.\n",
    "- TP / (TP + FP)로 구한다.\n",
    "- sklearn.metrics.precision_score(y_true, y_pred, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall (=Sensitivity)\n",
    "- 실제로 1인 데이터들 중 1로 맞게 예측한 데이터의 비율로서 재현율 혹은 민감도를 의미한다.\n",
    "- TP / (TP + FN)로 구한다.\n",
    "- sklearn.metrics.recall_score(y_true, y_pred, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specificity\n",
    "- 실제로 0인 데이터들 중 0으로 맞게 예측한 데이터의 비율로서 특이도를 의미한다.\n",
    "- TN / (TN + FP)로 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative predictive value\n",
    "- 예측을 0이라고 한 데이터 중 0으로 맞게 예측한 데이터의 비율을 의미한다.\n",
    "- TN / (TN + FN)로 구한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1-score 및 F$\\beta$-score\n",
    "- 정밀도와 재현율의 조화 평균으로 계산되는 지표이다.\n",
    "- F$\\beta$-score는 F1-score에서 구한 정밀도와 재현율의 균형(조화평균)에서 계수 $\\beta$에 따라 재현율에 가중치를 주어 조정한 지표이다.\n",
    "- 계수 $\\beta$가 1일 때는 F1-score, 2일 때는 F2-score가 된다.\n",
    "- class가 3개 이상인 다중 클래스(Multi-class)의 경우, f1_score의 파라미터 average를 None으로 설정하면 각 클래스에 대한 점수가 반환되고, 'samples', 'macro', 'micro', 'weighted'의 평균 타입을 설정하여 평균 점수를 구할 수 있다.\n",
    "- sklearn.metrics.f1_score(y_true, y_pred, *[, ...])\n",
    "- sklearn.metrics.fbeta_score(y_true, y_pred, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision-recall curve\n",
    "- 확률 임곗값(probability thresholds 혹은 cut-off value)에 따른 precision-recall의 변화를 보여줌으로써 최적의 확률 임곗값을 찾을 수 있도록 도와주는 curve이다.\n",
    "- 정밀도와 재현율은 어느 한 쪽의 값을 높이려 할 때 다른 쪽의 값은 낮아지는 trade-off 관계이다.\n",
    "- 따라서 모델 목적에 따라 둘 중 어느 지표에 더 중점을 둘 지 정할 수 있다.\n",
    "- 잘못된 예측을 줄이고 싶다면 정밀도를 중시하고, 실제 양성인 데이터를 양성으로 최대한 예측하고 싶다면 재현율을 중시한다.\n",
    "- 확률 임곗값이 커질수록 FP는 줄어들고, FN는 많아지기 때문에 정밀도(precision=TP/(TP+FP))는 커지고, 재현율(recall=TP/(TP+FN))은 작아지게 된다.\n",
    "- 따라서 정밀도를 중시하는 경우, 확률 임곗값을 높게 잡으면 된다.\n",
    "- sklearn.metrics.precision_recall_curve(y_true, probas_pred, *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report\n",
    "- 클래스 별로 precision, recall, f1-score, accuracy 등 평가 지표를 통해 분류 성능을 파악할 수 있는 report를 제공한다.\n",
    "- sklearn.metrics.classification_report(y_true, y_pred, *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "- 인덱스에 실제 클래스들, 컬럼에 예측 클래스들로 분류된 데이터 개수를 혼동 행렬로 반환한다.\n",
    "- sklearn.metrics.confusion_matrix(y_true, y_pred, *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilabel confusion matrix\n",
    "- 앞서 언급한 confusion matrix와 달리 각 클래스와 나머지 클래스에 대한 비교 방식(One-vs-rest way)으로 이진 분류한 confusion matrix를 각 클래스 별로 반환한다.\n",
    "- sklearn.metrics.multilabel_confusion_matrix(y_true, y_pred, *)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve (Receiver operating characteristic curve)\n",
    "- 예측값을 양성으로 판단하는 확률 임곗값을 1에서 0으로 움직일 때의 거짓 양성 비율(False positive rate)과 참 양성 비율(True positive rate)을 그래프의 (x, y)축으로 나타낸 것이다.\n",
    "- 모든 데이터를 정확하게 예측했을 경우 ROC 곡선을 (0, 1)을 지나며 AUC는 1이다.\n",
    "- 랜덤 예측의 경우 ROC 곡선은 보통 대각선을 지나며 AUC는 0.5 정도이다.\n",
    "- FPR은 실제 거짓인 데이터를 양성으로 잘못 예측한 비율로서, (FP / (FP + TN)) 혹은 (1 - Specificity)로 구한다.\n",
    "- TPR은 실제 참인 데이터를 양성으로 올바르게 예측한 비율로서, (TP / (TP + FN)) 혹은, Recall로 구한다.\n",
    "- sklearn.metrics.roc_curve(y_true, y_score, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUC (Area under the ROC curve)\n",
    "- ROC curve의 아래 면적을 가리킨다.\n",
    "- 분류 성능이 좋을 수록 AUC는 1에 가깝고 분류가 무작위면 0.5에 가깝다.\n",
    "- 분류를 완전 반대로 한 경우는 0이 된다.\n",
    "- 지니 계수(Gini coefficient)는 (2 * AUC - 1)로 계산하며 AUC와 선형 관계이다.\n",
    "- 평가 지표가 지니 계수라면 평가 지표가 AUC나 거의 마찬가지인 셈이다.\n",
    "- 분류 성능이 좋을 수록 지니 계수는 1에 가깝고, 무작위 분류이면 0, 완전 반대로 분류될 경우 -1을 갖게 된다.\n",
    "- sklearn.metrics.roc_auc_score(y_true, y_score, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log-loss\n",
    "- 이진분류의 평가 지표로서 logistic loss 혹은 cross-entropy loss라 부르기도 한다.\n",
    "- 실제값을 예측하는 확률에 로그를 취하여 부호를 반전시킨 값이다.\n",
    "- 로그 손실이 낮을수록 좋은 지표이다.\n",
    "- $-\\frac{1}{N}\\sum_{i=1}^{N}logp^{'}i$로 구한다.\n",
    "- sklearn.metrics.log_loss(y_true, y_pred, *[, eps, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이익도표 (Lift chart = Decile gains chart)\n",
    "- Lift는 모델이 다른 확률 컷오프에 대해 비교적 드문 1을 얼마나 더 효과적으로 구분하는지 나타내는 측정 지표이다.\n",
    "- 가장 1로 분류될 가능성이 높은 것부터 매 십분위(Decile)마다 이를 계산한다.\n",
    "- 예를 들어, 2000명의 고객 중 381명이 상품을 구매한 경우에 데이터셋의 각 관측치에 대한 예측 확률을 내림차순으로 정렬한다.\n",
    "- 이후 데이터를 10개의 구간으로 나눈 다음 각 구간의 반응률(Response)을 산출한다.\n",
    "- 또한, 기본 향상도(Baseline lift)에 비해 반응률이 몇 배나 높은지 향상도(Lift)를 계산한다.\n",
    "- 이익도표의 각 등급은 예측 확률에 따라 매겨진 순위이기 때문에 상위 등급에서는 더 높은 반응률을 보이는 것이 좋은 모형이라고 평가할 수 있다.\n",
    "- 등급의 내림차순으로 향상도가 급격하게 감소할수록 좋은 모형이라고 할 수 있고, 각 등급별로 향상도가 들쭉날쭉하면 좋은 모형이라고 볼 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCC (매튜상관계수, Matthews correlation coefficient)\n",
    "- 불균형한 데이터의 모델 성능을 적절히 평가하기 쉬운 지표이다.\n",
    "- 이 지표는 -1부터 +1 사이 범위의 값을 가진다.\n",
    "- 그 값이 +1일 때는 완벽한 예측, 0일 때는 랜덤한 예측, -1일 때는 완전 반대 예측을 한 것이다.\n",
    "- F1-score와 달리 양성과 음성을 대칭 취급하므로 실제값과 예측값의 양성과 음성을 서로 바꿔도 점수는 같다.\n",
    "- 양성이 많을 때와 음성이 많을 때의 각각의 균형이 서로 정확히 역전된 상황에서, F1-score는 TN을 사용하지 않고 계산하므로 값이 크게 달라지지만 MCC의 경우에는 값이 바뀌는 일이 없다.\n",
    "- sklearn.metrics.matthews_corrcoef(y_true, y_pred, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QWK (Quadratic weighted kappa)\n",
    "- 다중 클래스 분류에서 클래스 간에 순서 관계가 있을 때 사용한다.\n",
    "- 각 행 데이터의 예측값이 어느 클래스에 속하는지 제출한다.\n",
    "- 완전한 예측일 때는 1, 랜덤 예측일 때는 0, 랜덤보다 나쁜 예측일 때는 마이너스 값이 된다.\n",
    "- sklearn.metrics.cohen_kappa_score(y_true, y_pred, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 데이터 불러오기\n",
    "X, y = load_breast_cancer()['data'], load_breast_cancer()['target']\n",
    "\n",
    "# 데이터 표준화 및 분할\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=10)\n",
    "\n",
    "# 로지스틱 회귀 적합 및 예측\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "pred1 = lr.predict(X_test)\n",
    "\n",
    "# SVM 분류 및 적합 및 예측\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)\n",
    "pred2 = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logistic Regression Vs. SVM\n",
      "accuracy: 0.97, 0.97\n",
      "precision: 0.98, 0.96\n",
      "recall: 0.98, 0.99\n",
      "f1_score: 0.98, 0.97\n",
      "log_loss: 0.97, 1.21\n",
      "MCC: 0.94, 0.93\n",
      "cohen: 0.94, 0.92\n"
     ]
    }
   ],
   "source": [
    "# 2개의 분류 모델 평가 및 비교\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, log_loss, matthews_corrcoef, cohen_kappa_score, confusion_matrix\n",
    "\n",
    "titles = ['accuracy', 'precision', 'recall', 'f1_score', 'log_loss', 'MCC', 'cohen']\n",
    "functions = [accuracy_score, precision_score, recall_score, f1_score, log_loss, matthews_corrcoef, cohen_kappa_score]\n",
    "\n",
    "print(\">> Logistic Regression Vs. SVM\")\n",
    "for title, function in zip(titles, functions):\n",
    "    score1 = function(y_test, pred1)\n",
    "    score2 = function(y_test, pred2)\n",
    "    print(f\"{title}: {round(score1, 2)}, {round(score2, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Logistic regression confusion matrix: \n",
      "         예측값(N)  예측값(P)\n",
      "실제값(N)      51       2\n",
      "실제값(P)       2      88\n",
      "\n",
      "\n",
      ">> SVM confusion matrix: \n",
      "         예측값(N)  예측값(P)\n",
      "실제값(N)      49       4\n",
      "실제값(P)       1      89\n",
      "\n",
      "\n",
      ">> Logistic regression report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        53\n",
      "           1       0.98      0.98      0.98        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.97      0.97       143\n",
      "weighted avg       0.97      0.97      0.97       143\n",
      "\n",
      ">> SVM report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95        53\n",
      "           1       0.96      0.99      0.97        90\n",
      "\n",
      "    accuracy                           0.97       143\n",
      "   macro avg       0.97      0.96      0.96       143\n",
      "weighted avg       0.97      0.97      0.96       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix와 classificatoin report 비교\n",
    "lr_cm = pd.DataFrame(confusion_matrix(y_test, pred1), index=['실제값(N)', '실제값(P)'], columns=['예측값(N)', '예측값(P)'])\n",
    "svm_cm = pd.DataFrame(confusion_matrix(y_test, pred2), index=['실제값(N)', '실제값(P)'], columns=['예측값(N)', '예측값(P)'])\n",
    "\n",
    "print(f\">> Logistic regression confusion matrix: \\n {lr_cm}\")\n",
    "print(\"\\n\")\n",
    "print(f\">> SVM confusion matrix: \\n {svm_cm}\")\n",
    "\n",
    "lr_report = classification_report(y_test, pred1)\n",
    "svm_report = classification_report(y_test, pred2)\n",
    "print(\"\\n\")\n",
    "print(f\">> Logistic regression report: {lr_report}\")\n",
    "print(f\">> SVM report: {svm_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 모델의 성능 시각화: Precision-recall curve, ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score\n",
    "\n",
    "# 앞서 적합한 로지스틱 회귀 모델로 예측값, 예측확률값 가져오기\n",
    "pred = lr.predict(X_test)\n",
    "prob = lr.predict_proba(X_test)[:, 1] # 1이 될 probability thresholds\n",
    "\n",
    "# 1) precision-recall의 차이가 최소가 되는 지점 찾기\n",
    "# precision-recall trade-off\n",
    "# precision-recall trade-off plot을 통해 Precision과 Recall의 차이가 최소가 되는 cut-off value(0.519)를 확인할 수 있다.\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, prob)\n",
    "thresholds = list(thresholds) + [1]\n",
    "idx = np.argmin(np.abs(precision - recall))\n",
    "best_threshold = thresholds[idx]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "ax[0].set_title(\"Precision-recall trade-off\")\n",
    "ax[0].plot(thresholds, precision, label='precision')\n",
    "ax[0].plot(thresholds, recall, label='recall', linestyle='dashed')\n",
    "ax[0].plot(best_threshold, recall[idx], marker='o', color='red', label='best_threshold')\n",
    "ax[0].text(0.6, 0.9, f\"best threshold: {round(best_threshold, 3)}\", color='red')\n",
    "ax[0].legend()\n",
    "ax[0].set_xlabel('probability thresholds')\n",
    "ax[0].set_ylabel('precision & recall')\n",
    "\n",
    "# 2) ROC AUC가 최대가 되는 지점 찾기\n",
    "# ROC curve & best threshold\n",
    "# ROC curve plot을 통해 AUC가 최대가 되는 cut-off value(0.426)를 확인할 수 있다.\n",
    "fpr, tpr, thresholds = roc_curve(y_test, prob)\n",
    "auc = roc_auc_score(y_test, prob)\n",
    "\n",
    "# best thresholds(=cut-off value) 찾기\n",
    "# Youden Index (Youden's J statistic): recall - (1 - specificity)의 최대 지점\n",
    "J = tpr - fpr\n",
    "idx = np.argmax(J)\n",
    "\n",
    "best_threshold = thresholds[idx]\n",
    "best_tpr = tpr[idx]\n",
    "best_fpr = fpr[idx]\n",
    "\n",
    "ax[1].set_title(\"ROC curve & best threshold\")\n",
    "ax[1].plot(fpr, tpr, label=\"AUC\")\n",
    "ax[1].plot([0, 1], [0, 1], linestyle='dashed')\n",
    "ax[1].plot(best_fpr, best_tpr, marker='o', color='red', label='best threshold')\n",
    "ax[1].text(0.1, 0.9, f\"best thresholds: {round(best_threshold, 3)}\", color='red')\n",
    "ax[1].text(0.1, 0.8, f'AUC: {round(auc, 3)}', color='red')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel(\"FPR\")\n",
    "ax[1].set_ylabel(\"TPR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분류 모델의 성능 시각화: lift chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_lift: 0.63\n",
      "lift chart:\n",
      "         pred_prob  y_true  captured_R         R      lift\n",
      "Decile                                                   \n",
      "1       13.999467      14    0.155556  0.979021  1.555556\n",
      "2       13.996522      14    0.155556  0.979021  1.555556\n",
      "3       13.988619      14    0.155556  0.979021  1.555556\n",
      "4       13.966385      14    0.155556  0.979021  1.555556\n",
      "5       13.812808      14    0.155556  0.979021  1.555556\n",
      "6       13.112845      13    0.144444  0.909091  1.444444\n",
      "7        6.829995       7    0.077778  0.489510  0.777778\n",
      "8        0.269139       0    0.000000  0.000000  0.000000\n",
      "9        0.004845       0    0.000000  0.000000  0.000000\n",
      "10       0.000003       0    0.000000  0.000000  0.000000 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimmi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 예측된 확률과 실제 클래스를 확률 내림차순으로 정렬\n",
    "rank = pd.DataFrame({\n",
    "    \"pred_prob\" : prob,\n",
    "    \"y_true\" : y_test\n",
    "}).sort_values(by=\"pred_prob\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 10개 구간으로 나눔\n",
    "rank['Decile'] = 10 # 임시로 입력\n",
    "start = 0\n",
    "end = len(rank) // 10\n",
    "end_start = end - start\n",
    "decile = 1\n",
    "\n",
    "while end < len(rank):\n",
    "    for i in range(start, end):\n",
    "        rank['Decile'][i] = decile\n",
    "        \n",
    "    decile += 1\n",
    "    start = end\n",
    "    end += len(rank) // 10\n",
    "    \n",
    "# baseline lift 계산 및 실구매자수 집계\n",
    "total = len(y_test) # 전체 데이터 수\n",
    "count = y_test.sum() # 1(True)의 개수\n",
    "baseline_lift = count / total\n",
    "print(f\"baseline_lift: {round(baseline_lift, 2)}\")\n",
    "\n",
    "liftchart = rank.groupby('Decile').sum()\n",
    "\n",
    "# lift chart에 captured response, response, lift 추가\n",
    "liftchart['captured_R'] = liftchart['y_true'] / count\n",
    "liftchart['R'] = liftchart['y_true'] / (total / 10) # 10 = 등급수\n",
    "liftchart['lift'] = liftchart['R'] / baseline_lift\n",
    "print(f\"lift chart:\\n\", liftchart, \"\\n\")\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5, 5)\n",
    "plt.title(\"Lift chart\")\n",
    "plt.bar(liftchart.index, liftchart['lift'])\n",
    "plt.ylabel(\"Lift\")\n",
    "plt.xlabel(\"Decile\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class 분류 모델의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.82\n",
      "precision: [0.82 0.81 0.86]\n",
      "recall: [0.93 0.94 0.5 ]\n",
      "f1_score: [0.87 0.87 0.63]\n",
      "\n",
      "\n",
      ">>> classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.93      0.87        15\n",
      "           1       0.81      0.94      0.87        18\n",
      "           2       0.86      0.50      0.63        12\n",
      "\n",
      "    accuracy                           0.82        45\n",
      "   macro avg       0.83      0.79      0.79        45\n",
      "weighted avg       0.83      0.82      0.81        45\n",
      "\n",
      ">>> confusion matrix: \n",
      "         예측값(0)  예측값(1)  예측값(2)\n",
      "실제값(0)      14       0       1\n",
      "실제값(1)       1      17       0\n",
      "실제값(2)       2       4       6\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "# 데이터 불러오기\n",
    "load = load_wine()\n",
    "X = load['data'][:, :5]\n",
    "y = load['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=10)\n",
    "\n",
    "# 모델 적합\n",
    "svm = SVC(C=1, kernel='rbf', gamma='auto', probability=True)\n",
    "svm.fit(X_train, y_train)\n",
    "pred = svm.predict(X_test)\n",
    "prob = svm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# 모델 평가\n",
    "titles = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "functions = [accuracy_score, precision_score, recall_score, f1_score]\n",
    "\n",
    "for title, function in zip(titles, functions):\n",
    "    if function in [precision_score, recall_score, f1_score]:\n",
    "        params = {'average' : None} # 각 클래스 별 점수 반환을 위한 설정\n",
    "        score = function(y_test, pred, **params)\n",
    "    else:\n",
    "        score = function(y_test, pred)\n",
    "        \n",
    "    print(f\"{title}: {score.round(2)}\")\n",
    "    \n",
    "print(\"\\n\")\n",
    "print(f\">>> classification report: \\n {classification_report(y_test, pred)}\")\n",
    "print(f\">>> confusion matrix: \\n {pd.DataFrame(confusion_matrix(y_test, pred), index=['실제값(0)', '실제값(1)', '실제값(2)'], columns=['예측값(0)', '예측값(1)', '예측값(2)'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-class 분류 모델의 성능 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "y_train2 = label_binarize(y_train, classes=np.unique(y_train))\n",
    "y_test2 = label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "ovr_clf = OneVsRestClassifier(svm) # 앞서 적합한 모델 입력\n",
    "ovr_clf.fit(X_train, y_train2)\n",
    "prob3 = ovr_clf.predict_proba(X_test)\n",
    "\n",
    "fprs, tprs, aucs, best_thresholds, best_idx = [], [], [], [], []\n",
    "for i in range(len(np.unique(y_train))):\n",
    "    fpr, tpr, thresholds = roc_curve(y_test2[:, i], prob3[:, i])\n",
    "    idx = np.argmax(tpr - fpr) # 최적의 threshold idx\n",
    "    best_threshold = thresholds[idx] # 최적의 threshold 값\n",
    "    auc = roc_auc_score(y_test2[:, i], prob3[:, i])\n",
    "    \n",
    "    fprs.append(fpr) # 해당 클래스의 최적값들을 리스트에 추가\n",
    "    tprs.append(tpr)\n",
    "    aucs.append(auc)\n",
    "    \n",
    "    best_thresholds.append(best_threshold)\n",
    "    best_idx.append(idx)\n",
    "    \n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.plot(fprs[i], tprs[i], label='ROC curve')\n",
    "    ax.set_title(f\"class {i} (AUC: {round(aucs[i], 3)})\")\n",
    "    ax.plot(fprs[i][best_idx[i]], tprs[i][best_idx[i]], marker='o', color='red')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-3. 군집모델 평가 지표\n",
    "- 실제 군집값이 없는 경우의 군집모델 평가 지표는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Silhouette coefficient\n",
    "- 군집 내의 응집도와 군집 간 분리도를 이용한 지표로 군집 내 요소 간의 거리가 짧고 서로 다른 군집 간 거리가 멀수록 값이 커진다.\n",
    "- 완벽한 군집화는 1, 군집화가 전혀 이루어지지 않은 경우 -1을 가진다.\n",
    "- DBSCAN과 같은 밀도 기반 클러스터링 기법에서 더 높은 점수를 내는 경향이 있다.\n",
    "- 밀집된 클러스터가 좋긴 하지만 모양이 복잡할 때는 밀집도를 활용한 평가가 잘 들어맞지 않다.\n",
    "- sklearn.metrics.silhouette_score(X, labels, *[, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calinski and Harabasz score (=Variance ratio criterion)\n",
    "- 클러스터 내 분산과 클러스터 간 분산 간의 비율을 나타낸다.\n",
    "- 값이 클수록 클러스터들이 조밀하고 잘 분리되었다고 판단한다.\n",
    "- 계산이 빠르다.\n",
    "- sklearn.metrics.calinski_harabasz_score(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Davies-Bouldin score\n",
    "- 가장 유사한 군집이 있는 각 군집의 \"평균\" 유사성 측정값으로, 유사성은 군집 내 거리와 군집 간 거리의 비율을 나타낸다.\n",
    "- 이 값이 낮을수록 잘 된 클러스터링으로 본다.\n",
    "- 최소 score값은 0이다.\n",
    "- 실루엣 스코어보다 계산이 간단하다.\n",
    "- 이 스코어는 계산에 있어서 포인트 단위 거리만 사용하므로 데이터세트 고유의 수량과 기능만을 기반으로 한다.\n",
    "- sklearn.metrics.davies_bouldin_score(X, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제 군집값이 있는 경우의 군집모델 평가 지표는 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARI (Adjusted rand index)\n",
    "- 무작위로 할당된 군집에 대한 ARI 값은 0에 가까워지며 무작위 할당보다 나쁘게 군집되면 음수값을 가질 수 있다.\n",
    "- -0.5 ~ 1 사이의 값을 가지며, 잘된 군집은 1에 가깝다.\n",
    "- sklearn.metrics.adjusted_rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMI (Normalized mutual information)\n",
    "- 0~1 사이의 값을 가지며, 실제 군집값과 예측 군집값의 상호 정보를 확인하여 상호 정보가 없는 독립일 때는 0, 완벽한 상관관계를 가질 때는 1로서 1에 가까울수록 잘된 군집으로 본다.\n",
    "- 이 측정값은 때때로 조정되지 않기 때문에 ARI가 더 선호되기도 한다.\n",
    "- sklearn.metrics.normalized_mutual_info_score(labels_true, labels_pred, *, average_method='arithmetic')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completeness score (완전성)\n",
    "- 예측한 군집의 모든 데이터 포인트들이 실제 군집과 동일하게 한 군집을 이룰 때 완전성을 만족한다.\n",
    "- 0~1 사이 값을 가지며 1에 가까울수록 잘 분리되었다고 본다.\n",
    "- 측정값은 레이블의 절댓값과 상관없다. 예를 들어 0, 1, 2의 군집을 4, 5, 6으로 예측해도 각 클러스터의 데이터 포인트들만 동일하게 포함되어 있으면 적절한 score를 반환한다.\n",
    "- 이 metric은 대칭이 아니기 때문에 labels_true와 labels_pred의 순서가 바뀌면 다른 값을 반환하게 된다.\n",
    "- sklearn.metrics.completeness_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homogeneity score (동질성)\n",
    "- 예측한 모든 군집들이 실제 군집의 단일 클래스로만 이루어져 있을 때 동질성을 만족한다.\n",
    "- 0~1 사이 값을 가지며 1에 가까울수록 잘 분리되었다고 본다.\n",
    "- sklearn.metrics.homogeneity_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V-measure\n",
    "- Homogeneity score와 Completeness score의 조화평균을 의미한다.\n",
    "- 0~1 사이의 값을 가지며 1에 가까울수록 잘 분리되었다고 본다.\n",
    "- sklearn.metrics.v_measure_score(labels_true, labels_pred, *, beta=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rand Index (For two clusterings)\n",
    "- 모든 샘플 쌍을 고려하고, 예측 및 실제 군집에서 동일하거나 다른 군집에 할당된 쌍을 계산함으로써 두 군집 간의 유사성을 계산한다.\n",
    "- metrics.rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutual Information (For two clusterings)\n",
    "- 예측 및 실제 군집 간의 상호 정보를 확인하여 두 군집 간의 유사성을 계산한다.\n",
    "- metrics.mutual_info_score(labels_true, labels_pred, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, target = load_iris()['data'], load_iris()['target']\n",
    "\n",
    "# K-means clustering 적합\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(X)\n",
    "\n",
    "cluster = kmeans.predict(X) # 예측 군집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silhouette: [0.875 0.872 0.632]\n",
      "calinski: [0.875 0.872 0.632]\n",
      "davies: [0.875 0.872 0.632]\n"
     ]
    }
   ],
   "source": [
    "# 실제 군집값이 없는 경우\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "titles = ['silhouette', 'calinski', 'davies']\n",
    "functions = [silhouette_score, calinski_harabasz_score, davies_bouldin_score]\n",
    "for t, f in zip(titles, functions):\n",
    "    socre = f(X, cluster)\n",
    "    print(f\"{t}: {score.round(3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARI: 0.73\n",
      "NMI: 0.758\n",
      "completeness: 0.765\n",
      "homogeneity: 0.751\n",
      "v-measure: 0.758\n",
      "rand: 0.826\n",
      "MI: 0.765\n"
     ]
    }
   ],
   "source": [
    "# 실제 군집값이 있는 경우\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, completeness_score, homogeneity_score, v_measure_score, mutual_info_score, completeness_score, homogeneity_score, v_measure_score, mutual_info_score\n",
    "\n",
    "titles = ['ARI', 'NMI', 'completeness', 'homogeneity', 'v-measure', 'rand', 'MI']\n",
    "functions = [adjusted_rand_score, normalized_mutual_info_score, completeness_score, homogeneity_score, v_measure_score, mutual_info_score, completeness_score, homogeneity_score, v_measure_score, mutual_info_score]\n",
    "for t, f in zip(titles, functions):\n",
    "    score = f(target, cluster)\n",
    "    print(f\"{t}: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11-4. 거리 지표\n",
    "- 연속형 변수의 거리들은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euclidean distance\n",
    "- 데이터 간의 유사성을 측정할 때 많이 사용하는 대표적인 거리이다.\n",
    "- 통계적 개념이 내포되어 있지 않아서 변수들의 산포 정도가 전혀 감안되어 있지 않다.\n",
    "- $L_2$ distance라고도 한다.\n",
    "- $d(x, y) = \\sqrt{(x_1 - y_1)^2 + ... + (x_p - y_p)^2 }$\n",
    "- scipy.spatial.distance.euclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 표준화거리 (Standardized Euclidean distnace)\n",
    "- 해당변수의 표준편차로 척도 변환한 후 유클리드 거리를 계산하는 방법이다.\n",
    "- 표준화하게 되면 척도의 차이, 분산의 차이로 인한 왜곡을 피할 수 있다.\n",
    "- scipy.spatial.distance.seuclidean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan distance (=Cityblock distance)\n",
    "- 유클리디안 거리와 함께 가장 많이 사용되는 거리로 맨하탄 도시에서 건물에서 건물을 가기 위해 최단 거리를 구하기 위해 고안된 거리이다.\n",
    "- $L_1$ distance라고도 한다.\n",
    "- $d(x, y) = \\sum_{i=1}^{p}|x_i-y_i|$\n",
    "- scipy.spatial.distance.cityblock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mahalanobis distance\n",
    "- 통계적 개념이 포함된 거리이며 변수들의 산포를 고려하여 이를 표준화한 거리이다.\n",
    "- 두 벡터 사이의 거리를 산포를 의미하는 표본공분산으로 나눠주어야 하며, 그룹에 대한 사전 지식 없이는 표본공분산 S를 계산할 수 없으므로 사용하기 곤란하다.\n",
    "- $d(x, y) = \\sqrt{(x-y)^TS^{-1}(x-y)}$\n",
    "- $S^{-1}$은 공분산 행렬의 역행렬, T는 변환행렬\n",
    "- scipy.spatial.distance.mahalanobis(u, v, VI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minkowski distance\n",
    "- 맨하탄 거리와 유클리드 거리를 한 번에 표현한 거리이다.\n",
    "- m차원 민코프스키 공간에서의 거리로서 m=1일때 맨하탄 거리와 같고, m=2일 때 유클리드 거리와 같다.\n",
    "- $d(x, y) = [\\sum_{i=1}^{p}|x_i - y_i|^m]^{\\frac{1}{m}}$\n",
    "- scipy.spatial.distance.minkowski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Canberra distance\n",
    "- $d(x, y) = \\sum_{i=1}^{p} \\frac{|x_i - y_i|}{x_i + y_i}$\n",
    "- scipy.spatial.distance.Canberra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chebychev distance\n",
    "- $d(x, y) = max|x_i - y_i|$\n",
    "- scipy.spatial.distance.Chebyshev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타\n",
    "- corrrelation distance: scipy.spatial.distance.correlation\n",
    "- jensenshannon distance: scipy.spatial.distance.jensenshannon\n",
    "- Braycurtis distance: scipy.spatial.distance.braycurtis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance: 4.358898943540674 = 4.358898943540674\n",
      "seuclidean distance: 3.7815340802378077 = 3.7815340802378077\n",
      "Manhattan distance: 7 = 7\n",
      "minkowski distance(p=1): 7.0 = 7.0\n",
      "minkowski distance(p=2): 4.358898943540674 = 4.358898943540674\n",
      "mahalanobis distance: 4.701063709417263 = 4.701063709417263\n"
     ]
    }
   ],
   "source": [
    "# 연속형 변수의 거리들\n",
    "from scipy.spatial.distance import euclidean, seuclidean, cityblock, minkowski, mahalanobis\n",
    "\n",
    "NV1 = np.array([1, 5, 7, 9])\n",
    "NV2 = np.array([2, 4, 8, 13])\n",
    "\n",
    "V = np.array([0.1, 1, 10, 5]) # V = component variacnes (분산)\n",
    "IV = np.array([[1, 0.5, 0.5, 0.1], [0.1, 2, 1, 0.5], [0.5, 0.5, 1, 0.2], [1, 1, 1, 1]])\n",
    "# IV = The inverse of the covariance matrix (역공분산)\n",
    "\n",
    "# 유클리드 거리\n",
    "eu1 = euclidean(NV1, NV2)\n",
    "eu2 = np.sqrt(((NV1 - NV2)**2).sum())\n",
    "print(f\"Euclidean distance: {eu1} = {eu2}\")\n",
    "\n",
    "# 표준화 거리\n",
    "seu1 = seuclidean(NV1, NV2, V)\n",
    "seu2 = np.sqrt(((NV1 - NV2)**2 / V).sum())\n",
    "print(f\"seuclidean distance: {seu1} = {seu2}\")\n",
    "\n",
    "# 맨해튼 거리\n",
    "man1 = cityblock(NV1, NV2)\n",
    "man2 = np.abs(NV1 - NV2).sum()\n",
    "print(f\"Manhattan distance: {man1} = {man2}\")\n",
    "\n",
    "# 민코프스키 거리\n",
    "p = 1\n",
    "min1 = minkowski(NV1, NV2, p=1)\n",
    "min2 = ((np.abs(NV1 - NV2)**p).sum())**1 / p\n",
    "\n",
    "p = 2\n",
    "min3 = minkowski(NV1, NV2, p=2)\n",
    "min4 = np.sqrt(((np.abs(NV1 - NV2))**p).sum())\n",
    "print(f\"minkowski distance(p=1): {min1} = {min2}\")\n",
    "print(f\"minkowski distance(p=2): {min3} = {min4}\")\n",
    "\n",
    "# 마할라노비스 거리\n",
    "mah1 = mahalanobis(NV1, NV2, IV)\n",
    "mn = len(NV1)\n",
    "\n",
    "reshaped_mat1 = (NV1 - NV2).reshape(-1, mn) # 형태 변환 (1*4)\n",
    "result1 = np.dot(reshaped_mat1, IV) # np.dot을 통해 행렬곱을 진행\n",
    "\n",
    "reshaped_mat2 = (NV1 - NV2).reshape(-mn, 1) # 형태 변환 (4*1)\n",
    "result2 = np.dot(result1, reshaped_mat2)\n",
    "mah2 = float(np.sqrt(result2))\n",
    "print(f\"mahalanobis distance: {mah1} = {mah2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 범주형 변수들의 거리들은 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard distance\n",
    "- Boolean 속성으로 이루어진 두 개체 간의 거리 측정에 사용된다.\n",
    "- 한편, (1-자카드 거리)를 자카드 유사도(Jaccard similarity 혹은 Jaccard coefficient)라고 하며, 두 개체 간의 유사도 측정에 사용한다.\n",
    "- 자카드 유사도는 두 개체가 유사할 수록 1에 가깝고 다를수록 0에 가깝다.\n",
    "- 자카드 거리 = 1 - 자카드 유사도\n",
    "- 자카드 유사도 = $\\frac{|A \\cap B|}{|A \\cup B|}$\n",
    "- scipy.spatial.distance.jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine distance\n",
    "- 코사인 거리이다.\n",
    "- 한편, (1-코사인 거리)를 코사인 유사도(Cosine similairty)라고 하며, 문서를 유사도 기준으로 분류 혹은 그룹핑 할 때 유용하게 사용한다.\n",
    "- 두 개체의 벡터 내적의 코사인 값을 계산하여 코사인 유사도를 측정한다.\n",
    "- 코사인 유사도는 서로 같을수록 1, 서로 다를수록 -1의 값을 가진다.\n",
    "- 코사인 거리 = 1 - 코사인 유사도\n",
    "- 코사인 유사도: $\\frac{A \\cdot B}{||A||_2 \\cdot ||B||_2}$\n",
    "- $\\cdot$: 같은 인덱스(위치)에 있는 원소들끼리 곱해서 그 값들을 모두 합하라는 의미\n",
    "- $||A||_2$: $L_2$ 거리 즉, 유클리디안 거리\n",
    "- scipy.spatial.distance.cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기타\n",
    "- Dice dissimilarity: scipy.spatial.distance.dice\n",
    "- Hamming distance: scipy.spatial.distance.hamming\n",
    "- Kulsinski dissimialirty: scipy.spatial.distance.kulsinski\n",
    "- the Rogers-Tanimoto: scipy.spatial.distance.rogerstanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Boolean data]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Life</th>\n",
       "      <th>Life2</th>\n",
       "      <th>Life3</th>\n",
       "      <th>Life4</th>\n",
       "      <th>Love</th>\n",
       "      <th>Love2</th>\n",
       "      <th>Love3</th>\n",
       "      <th>Love4</th>\n",
       "      <th>Love5</th>\n",
       "      <th>Love6</th>\n",
       "      <th>Love7</th>\n",
       "      <th>Learn</th>\n",
       "      <th>Learn2</th>\n",
       "      <th>Learn3</th>\n",
       "      <th>Learn4</th>\n",
       "      <th>Learn5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc_1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc_2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Life  Life2  Life3  Life4  Love  Love2  Love3  Love4  Love5  Love6  \\\n",
       "doc_1     1      0      0      0     0      0      0      0      0      0   \n",
       "doc_2     1      1      1      1     1      1      1      1      1      1   \n",
       "\n",
       "       Love7  Learn  Learn2  Learn3  Learn4  Learn5  \n",
       "doc_1      0      1       1       1       1       1  \n",
       "doc_2      1      1       1       1       0       0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 범주형 변수의 거리들\n",
    "from scipy.spatial.distance import jaccard, cosine\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "# Boolean data 생성\n",
    "print(\"[Boolean data]\")\n",
    "bdf = pd.DataFrame({\n",
    "    \"Life\" : [1, 1],\n",
    "    \"Life2\" : [0, 1],\n",
    "    \"Life3\" : [0, 1],\n",
    "    \"Life4\" : [0, 1],\n",
    "    \"Love\" : [0, 1],\n",
    "    \"Love2\" : [0, 1],\n",
    "    \"Love3\" : [0, 1],\n",
    "    \"Love4\" : [0, 1],\n",
    "    \"Love5\" : [0, 1],\n",
    "    \"Love6\" : [0, 1],\n",
    "    \"Love7\" : [0, 1],\n",
    "    \"Learn\" : [1, 1],\n",
    "    \"Learn2\" : [1, 1],\n",
    "    \"Learn3\" : [1, 1],\n",
    "    \"Learn4\" : [1, 0],\n",
    "    \"Learn5\" : [1, 0]    \n",
    "}, index=[\"doc_1\", \"doc_2\"])\n",
    "\n",
    "doc_1 = np.array(bdf.loc['doc_1', :])\n",
    "doc_2 = np.array(bdf.loc['doc_2', :])\n",
    "bdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Jaccard distance: 0.75 = 0.75 = 0.75\n",
      "- Jaccard similarity: 0.25 = 0.25 = 0.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kimmi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:1765: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# 자카드 거리와 자카드 유사도 계산\n",
    "jac1 = jaccard(doc_1, doc_2) # scipy\n",
    "jac2 = pairwise_distances(bdf.values, metric='jaccard')[0][1] # sklearn\n",
    "\n",
    "check = pd.DataFrame(bdf.sum(), columns=['check'])\n",
    "union = len(check[check['check'] != 0])\n",
    "intersec = len(check[check['check'] == 2])\n",
    "\n",
    "jac3 = 1 - intersec / union\n",
    "print(f\"- Jaccard distance: {jac1} = {jac2} = {jac3}\")\n",
    "print(f\"- Jaccard similarity: {1-jac1} = {1-jac2} = {1-jac3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Frequency data]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Life</th>\n",
       "      <th>Love</th>\n",
       "      <th>Learn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>doc1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc2</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Life  Love  Learn\n",
       "doc1     1     0      5\n",
       "doc2     4     7      3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Frequency data 생성\n",
    "print(f\"[Frequency data]\")\n",
    "fdf = pd.DataFrame({\n",
    "    \"Life\" : [1, 4],\n",
    "    \"Love\" : [0, 7],\n",
    "    \"Learn\" : [5, 3]\n",
    "}, index=['doc1', 'doc2'])\n",
    "\n",
    "doc1 = np.array(fdf.loc['doc1', :])\n",
    "doc2 = np.array(fdf.loc['doc2', :])\n",
    "fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Cosine distance: 0.5635642195280153 = 0.5668372850418244 = 0.5668372850418244\n",
      "- Cosine similarity: 0.4364357804719847 = 0.4331627149581756 = 0.4331627149581756\n"
     ]
    }
   ],
   "source": [
    "# 코사인 거리와 코사인 유사도 계산\n",
    "cos1 = cosine(doc_1, doc_2) # scipy\n",
    "cos2 = pairwise_distances(fdf.values, metric='cosine')[0][1] # sklearn\n",
    "\n",
    "cossim = np.sum(doc1 * doc2) / ((np.sqrt(np.sum((doc1)**2))) * np.sqrt(np.sum((doc2)**2)))\n",
    "cos3 = 1 - cossim\n",
    "print(f\"- Cosine distance: {cos1} = {cos2} = {cos3}\")\n",
    "print(f\"- Cosine similarity: {1-cos1} = {1-cos2} = {1-cos3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연습문제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.\n",
    "- 다음과 같은 데이터로 'price'를 예측하는 모델을 생성한다면, 어떤 평가지표로 평가할 수 있는지 3개 이상의 평가지표를 예를 들어 설명하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_type</th>\n",
       "      <th>availability</th>\n",
       "      <th>size</th>\n",
       "      <th>total_sqft</th>\n",
       "      <th>bath</th>\n",
       "      <th>balcony</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Super</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>39.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plot</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Super</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1521.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  area_type  availability  size  total_sqft  bath  balcony   price\n",
       "0     Super             0     3      1056.0     2        1   39.07\n",
       "1      Plot             1     6      2600.0     5        3  120.00\n",
       "2     Super             1     5      1521.0     3        1   95.00"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realestate = pd.read_csv(\"https://raw.githubusercontent.com/algoboni/pythoncodebook1-1/main/practice8_BHP2.csv\")\n",
    "realestate.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터로 'price'를 예측하는 회귀 모델을 생성하는 경우 사용할 수 있는 평가지표는 결정계수, MSE, MAPE 등이 있다.\n",
    "# 결정계수는 데이터에 대한 설명력을 0~1로 표현할 수 있는데 그 값이 1에 가까울수록 해당 모델이 학습 데이터를 잘 설명한다고 볼 수 있다.\n",
    "\n",
    "# 또 다른 평가지표로 MSE, Mean Sqaured Error가 있다. 이는 실제값과 예측값의 차이를 제곱해 평균을 계산한 것이다.\n",
    "# 지표는 직관적이지만 예측 변수와 단위가 다르고, 이상치에 민감하다는 단점이 있다.\n",
    "\n",
    "# MAPE는 MAE를 퍼센트로 변환한 것으로서 예측값 대비 잔차의 비율을 의미한다.\n",
    "# 지표가 직관적이고 비율 변수이기 때문에 모델 간 성능을 비교하기 용이하다.\n",
    "# 한편, 비율로 해석이 의미있는 값에만 적용할 수 있고, 실제 값에 0이 포함될 경우 MAPE를 계산할 수 없다는 한계가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.\n",
    "- 다음과 같은 데이터로 'CUST_ID'를 적절한 군집으로 할당하는 모델을 생성한다면, 어떤 평가 지표로 평가할 수 있는지 2개 이상의 평가지표를 예를 들어 설명하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CUST_ID</th>\n",
       "      <th>BALANCE</th>\n",
       "      <th>BALANCE_FREQUENCY</th>\n",
       "      <th>PURCHASES</th>\n",
       "      <th>PURCHASES_FREQUENCY</th>\n",
       "      <th>PURCHASES_TRX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C10001</td>\n",
       "      <td>40.900749</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>95.40</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C10002</td>\n",
       "      <td>3202.467416</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C10003</td>\n",
       "      <td>2495.148862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>773.17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CUST_ID      BALANCE  BALANCE_FREQUENCY  PURCHASES  PURCHASES_FREQUENCY  \\\n",
       "0  C10001    40.900749           0.818182      95.40             0.166667   \n",
       "1  C10002  3202.467416           0.909091       0.00             0.000000   \n",
       "2  C10003  2495.148862           1.000000     773.17             1.000000   \n",
       "\n",
       "   PURCHASES_TRX  \n",
       "0              2  \n",
       "1              0  \n",
       "2             12  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://raw.githubusercontent.com/algoboni/pythoncodebook1-1/main/practice10_credit_card.csv\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터로 군집 모델을 생성하는 경우 사용할 수 있는 평가 지표는 실제 군집값이 없는 경우이기 때문에 실루엣 계수와 \n",
    "# Calinski and Harabasz score를 들 수 있다. 실루엣 계수는 군집 내의 응집도가 높고, 군집 간 분리도가 높을 수록 잘된 군집으로 1에 가까운\n",
    "# 값을 나타내고, 군집이 전혀 이루어지지 않은 경우 -1에 가까운 값을 나타낸다. Calinski and Harabasz score는 클러스터 내 분산과\n",
    "# 클러스터 간 분산 간의 비율을 나타내는데, 값이 클수록 클러스터들이 조밀하고 잘 분리되었다고 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "- 다음과 같은 데이터 '문서1'과 '문서2'의 유사성을 판단할 때 어떤 거리 지표를 사용해야 하는지 설명하시오,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>hello</th>\n",
       "      <th>one</th>\n",
       "      <th>is</th>\n",
       "      <th>temperature</th>\n",
       "      <th>you</th>\n",
       "      <th>I</th>\n",
       "      <th>banana</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>문서1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>문서2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     a  hello  one  is  temperature  you  I  banana\n",
       "문서1  0      1    0   1            0    0  0       0\n",
       "문서2  1      1    0   1            0    0  1       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame([[0,1,0,1,0,0,0,0], [1,1,0,1,0,0,1,1]], index=['문서1', '문서2'], columns=['a', 'hello', 'one', 'is', 'temperature', 'you', 'I', 'banana'])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 데이터와 같이 Boolean 속성으로 이루어진 두 개체 간의 거리를 측정할 때에는 자카드 거리(1-자카드 유사도)를 사용할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
